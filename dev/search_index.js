var documenterSearchIndex = {"docs":
[{"location":"#ItemResponseDatasets.jl","page":"Getting started","title":"ItemResponseDatasets.jl","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"This package provides a quick interface to get different item-response datasets, which could then be fit with IRT models. It could be useful for various types of benchmarking and evaluation.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"CurrentModule = ItemResponseDatasets","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"","category":"page"},{"location":"#MGKT","page":"Getting started","title":"MGKT","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"Modules = [ItemResponseDatasets.MGKT]","category":"page"},{"location":"#ItemResponseDatasets.MGKT","page":"Getting started","title":"ItemResponseDatasets.MGKT","text":"Taken from the Multifactor General Knowledge Test (MGKT) obtained from OpenPsychometrics.org.\n\nQuoting the README:\n\n\"This data was collected through an on-line general knowledge test. Data collection took place 2017-2018. Users were motivated to take the test to obtain personalized results.\n\nThis test used a unique question format, where each question was of a type that could have multiple correct answers. In each question, 10 answers were displayed to the respondent and they were told that 5 were correct and to select as many as they knew but not to guess.\n\nThe test consisted of 32 questions. They were shown to each subject in a random order.\"\n\n\n\n\n\n","category":"module"},{"location":"#ItemResponseDatasets.MGKT.get_marked_df-Tuple{}","page":"Getting started","title":"ItemResponseDatasets.MGKT.get_marked_df","text":"This function gets a marked version of the MGTK.\n\n\n\n\n\n","category":"method"},{"location":"#ItemResponseDatasets.MGKT.get_mgkt-Tuple{}","page":"Getting started","title":"ItemResponseDatasets.MGKT.get_mgkt","text":"Gets the raw MGKT as a DataFrame.\n\n\n\n\n\n","category":"method"},{"location":"#VocabIQ","page":"Getting started","title":"VocabIQ","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"Modules = [ItemResponseDatasets.VocabIQ]","category":"page"},{"location":"#ItemResponseDatasets.VocabIQ","page":"Getting started","title":"ItemResponseDatasets.VocabIQ","text":"Taken from the Vocabulary IQ Test (VocabIQ) obtained from OpenPsychometrics.org.\n\nQuoting the README:\n\n\"This data was collected on-line through an interactive test titled \"Vocabulary IQ Test\" between July 2017 and March 2018.\n\nThe main body of the test had 45 vocabulary questions. Each question was a list of five words. Subjects were instructed to select the two on the list that had the same meaning. Subjects were also instructed to not guess and were told there was a -0.35 point penalty for a wrong answer.\"\n\n\n\n\n\n","category":"module"},{"location":"#ItemResponseDatasets.VocabIQ.get_marked_df-Tuple{}","page":"Getting started","title":"ItemResponseDatasets.VocabIQ.get_marked_df","text":"This function gets a marked version of VocabIQ.\n\n\n\n\n\n","category":"method"},{"location":"#ItemResponseDatasets.VocabIQ.get_viqt-Tuple{}","page":"Getting started","title":"ItemResponseDatasets.VocabIQ.get_viqt","text":"Gets the raw VocabIQ as a DataFrame.\n\n\n\n\n\n","category":"method"}]
}
